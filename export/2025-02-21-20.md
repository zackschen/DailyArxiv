# Continual Learning
## From RAG to Memory: Non-Parametric Continual Learning for Large Language Models
- **Url**: http://arxiv.org/abs/2502.14802v1
- **Authors**: ['Bernal Jiménez Gutiérrez', 'Yiheng Shu', 'Weijian Qi', 'Sizhe Zhou', 'Yu Su']
- **Abstrat**: Our ability to continuously acquire, organize, and leverage knowledge is a key feature of human intelligence that AI systems must approximate to unlock their full potential. Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new information. However, its reliance on vector retrieval hinders its ability to mimic the dynamic and interconnected nature of human long-term memory. Recent RAG approaches augment vector embeddings with various structures like knowledge graphs to address some of these gaps, namely sense-making and associativity. However, their performance on more basic factual memory tasks drops considerably below standard RAG. We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in HippoRAG and enhances it with deeper passage integration and more effective online use of an LLM. This combination pushes this RAG system closer to the effectiveness of human long-term memory, achieving a 7% improvement in associative memory tasks over the state-of-the-art embedding model while also exhibiting superior factual knowledge and sense-making memory capabilities. This work paves the way for non-parametric continual learning for LLMs. Our code and data will be released at https://github.com/OSU-NLP-Group/HippoRAG.


**Summary**: 

- (1): 本文的研究背景是AI系统需要近似人类不断获取、组织和利用知识的能力，以实现更高的智能水平，特别是在大规模语言模型（LLMs）领域的持续学习能力。 

- (2): 过去的方法主要是检索增强生成（RAG），其依赖简单的向量检索，导致无法有效捕捉人类长时记忆的动态性和关联性。本文提出的HippoRAG 2通过改进个性化PageRank算法，解决了基本事实记忆任务表现不佳的问题，使得RAG系统在事实、意义理解和关联性任务上具有更好的效果。这种方法动机明确，旨在提升LLMs的长期记忆效能。 

- (3): 本文的贡献在于提出HippoRAG 2框架，它在事实记忆、意义理解和关联性任务上全面超越标准RAG，并在关联性记忆任务上相较于最新的嵌入模型提高了7%的表现。 

- (4): 本文采用的研究方法论是基于个性化PageRank算法，增强了对话段落的整合和LLM的在线使用，致力于更好地模拟人类的长期记忆机制。 

- (5): 本文方法在事实记忆、意义理解和关联性记忆任务上均取得了显著的性能提升，证明了其目标的可实现性。

